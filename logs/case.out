#################### DATA ADAPTING FOR GNN #######################
Elaborazione case:  40  in modalità:  train
Elaborazione case:  50  in modalità:  train
Elaborazione case:  60  in modalità:  train
Elaborazione case:  70  in modalità:  train
Elaborazione case:  80  in modalità:  train
Elaborazione case:  90  in modalità:  train
Elaborazione case:  100  in modalità:  train
Elaborazione case:  120  in modalità:  train
Elaborazione case:  130  in modalità:  train
Elaborazione case:  140  in modalità:  train
Elaborazione case:  150  in modalità:  train
Trasformazione file di train completata!
Elaborazione case:  110  in modalità:  val
Trasformazione file di val completata!
Running on :  cuda
PARAMETER SET: k:70, laten_dim:20, alpha:0.01, lr:0.01
#################### CREATING Inner DATASET #######################
Processing...
Taking Data at Re n.:  40 in  train  mode.
Taking Data at Re n.:  50 in  train  mode.
Taking Data at Re n.:  60 in  train  mode.
Taking Data at Re n.:  70 in  train  mode.
Taking Data at Re n.:  80 in  train  mode.
Taking Data at Re n.:  90 in  train  mode.
Taking Data at Re n.:  100 in  train  mode.
Taking Data at Re n.:  120 in  train  mode.
Taking Data at Re n.:  130 in  train  mode.
Taking Data at Re n.:  140 in  train  mode.
Taking Data at Re n.:  150 in  train  mode.
Done!
Processing...
Taking Data at Re n.:  110 in  val  mode.
Done!
#################### DSS NET parameter #######################
Latent space dim :  20
Number of updates :  70
Gamma (loss function) :  0.5
Alpha (reduction correction) : 0.01
LR (Learning rate): 0.01
#################### CREATING NETWORKS #######################
#################### TRAINING #######################
Epoch 9424, 27% 	 train_loss: 3.18565e-05
Epoch 9424, 54% 	 train_loss: 3.19611e-05
Epoch 9424, 81% 	 train_loss: 8.08605e-05
Training loss = 1.95051e-04
Validation loss = 3.51187e-04
Training finished, took 170424.02s
Epoch 9425, 27% 	 train_loss: 3.56990e-05
Epoch 9425, 54% 	 train_loss: 3.42222e-05
Epoch 9425, 81% 	 train_loss: 4.83031e-05
Training loss = 1.51434e-04
Validation loss = 2.68088e-04
Training finished, took 170442.12s
Epoch 9426, 27% 	 train_loss: 4.33576e-05
Epoch 9426, 54% 	 train_loss: 2.70350e-05
Epoch 9426, 81% 	 train_loss: 4.25118e-05
Training loss = 1.46255e-04
Validation loss = 2.18079e-04
Training finished, took 170460.23s
Epoch 9427, 27% 	 train_loss: 2.53698e-05
Epoch 9427, 54% 	 train_loss: 2.85177e-05
Epoch 9427, 81% 	 train_loss: 5.48218e-05
Training loss = 1.49757e-04
Validation loss = 3.48409e-04
Training finished, took 170478.36s
Epoch 9428, 27% 	 train_loss: 5.48757e-05
Epoch 9428, 54% 	 train_loss: 4.29284e-05
Epoch 9428, 81% 	 train_loss: 6.12146e-05
Training loss = 2.10507e-04
Validation loss = 2.55447e-04
Training finished, took 170496.46s
Epoch 9429, 27% 	 train_loss: 4.20080e-05
Epoch 9429, 54% 	 train_loss: 2.90828e-05
Epoch 9429, 81% 	 train_loss: 6.20009e-05
Training loss = 1.75977e-04
Validation loss = 2.60912e-04
Training finished, took 170514.59s
Epoch 9430, 27% 	 train_loss: 2.95423e-05
Epoch 9430, 54% 	 train_loss: 3.04547e-05
Epoch 9430, 81% 	 train_loss: 5.88855e-05
Training loss = 1.61697e-04
Validation loss = 3.32720e-04
Training finished, took 170532.71s
Epoch 9431, 27% 	 train_loss: 4.58375e-05
Epoch 9431, 54% 	 train_loss: 3.92399e-05
Epoch 9431, 81% 	 train_loss: 6.04279e-05
Training loss = 1.87685e-04
Validation loss = 3.01800e-04
Training finished, took 170550.82s
Epoch 9432, 27% 	 train_loss: 4.20216e-05
Epoch 9432, 54% 	 train_loss: 3.42703e-05
Epoch 9432, 81% 	 train_loss: 4.96352e-05
Training loss = 1.63721e-04
Validation loss = 2.64886e-04
Training finished, took 170568.93s
Epoch 9433, 27% 	 train_loss: 4.20445e-05
Epoch 9433, 54% 	 train_loss: 4.10335e-05
Epoch 9433, 81% 	 train_loss: 6.68708e-05
Training loss = 2.07734e-04
Validation loss = 3.63028e-04
Training finished, took 170587.05s
Epoch 9434, 27% 	 train_loss: 5.68701e-05
Epoch 9434, 54% 	 train_loss: 3.35506e-05
Epoch 9434, 81% 	 train_loss: 9.36946e-05
Training loss = 2.56361e-04
Validation loss = 2.70753e-04
Training finished, took 170605.18s
Epoch 9435, 27% 	 train_loss: 3.74350e-05
Epoch 9435, 54% 	 train_loss: 3.38191e-05
Epoch 9435, 81% 	 train_loss: 7.75028e-05
Training loss = 2.09236e-04
Validation loss = 3.75382e-04
Training finished, took 170623.37s
Epoch 9436, 27% 	 train_loss: 5.48805e-05
Epoch 9436, 54% 	 train_loss: 3.48777e-05
Epoch 9436, 81% 	 train_loss: 6.91089e-05
Training loss = 2.12604e-04
Validation loss = 2.46954e-04
Training finished, took 170641.48s
Epoch 9437, 27% 	 train_loss: 2.80674e-05
Epoch 9437, 54% 	 train_loss: 3.38103e-05
Epoch 9437, 81% 	 train_loss: 7.28145e-05
Training loss = 1.77692e-04
Validation loss = 3.55163e-04
Training finished, took 170659.60s
Epoch 9438, 27% 	 train_loss: 5.65997e-05
Epoch 9438, 54% 	 train_loss: 3.24057e-05
Epoch 9438, 81% 	 train_loss: 4.85455e-05
Training loss = 1.74285e-04
Validation loss = 2.54971e-04
Training finished, took 170677.72s
Epoch 9439, 27% 	 train_loss: 3.71671e-05
Epoch 9439, 54% 	 train_loss: 2.78627e-05
Epoch 9439, 81% 	 train_loss: 4.71343e-05
Training loss = 1.48751e-04
Validation loss = 2.49579e-04
Training finished, took 170695.83s
Epoch 9440, 27% 	 train_loss: 3.36962e-05
Epoch 9440, 54% 	 train_loss: 3.04578e-05
Epoch 9440, 81% 	 train_loss: 6.50828e-05
Training loss = 1.78059e-04
Validation loss = 3.01805e-04
Training finished, took 170713.93s
Epoch 9441, 27% 	 train_loss: 4.56039e-05
Epoch 9441, 54% 	 train_loss: 3.78861e-05
Epoch 9441, 81% 	 train_loss: 5.61529e-05
Training loss = 1.93301e-04
Validation loss = 2.63851e-04
Training finished, took 170732.04s
Epoch 9442, 27% 	 train_loss: 3.58818e-05
Epoch 9442, 54% 	 train_loss: 3.05529e-05
Epoch 9442, 81% 	 train_loss: 7.06721e-05
Training loss = 1.90592e-04
Validation loss = 3.08568e-04
Training finished, took 170750.15s
Epoch 9443, 27% 	 train_loss: 2.55235e-05
Epoch 9443, 54% 	 train_loss: 3.02006e-05
Epoch 9443, 81% 	 train_loss: 6.23527e-05
Training loss = 1.65836e-04
Validation loss = 2.78017e-04
Training finished, took 170768.25s
Epoch 9444, 27% 	 train_loss: 4.39181e-05
Epoch 9444, 54% 	 train_loss: 3.09851e-05
Epoch 9444, 81% 	 train_loss: 4.37496e-05
Training loss = 1.56577e-04
Validation loss = 2.76830e-04
Training finished, took 170786.37s
Epoch 9445, 27% 	 train_loss: 4.13261e-05
Epoch 9445, 54% 	 train_loss: 3.05369e-05
Epoch 9445, 81% 	 train_loss: 6.35806e-05
Training loss = 1.87782e-04
Validation loss = 2.75232e-04
Training finished, took 170804.49s
Epoch 9446, 27% 	 train_loss: 3.25008e-05
Epoch 9446, 54% 	 train_loss: 3.31256e-05
Epoch 9446, 81% 	 train_loss: 6.85537e-05
Training loss = 1.74302e-04
Validation loss = 2.67716e-04
Training finished, took 170822.62s
Epoch 9447, 27% 	 train_loss: 4.21890e-05
Epoch 9447, 54% 	 train_loss: 3.28051e-05
Epoch 9447, 81% 	 train_loss: 4.93263e-05
Training loss = 1.61604e-04
Validation loss = 2.80533e-04
Training finished, took 170840.73s
Epoch 9448, 27% 	 train_loss: 3.82747e-05
Epoch 9448, 54% 	 train_loss: 2.70656e-05
Epoch 9448, 81% 	 train_loss: 5.26444e-05
Training loss = 1.59663e-04
Validation loss = 2.54088e-04
Training finished, took 170858.86s
Epoch 9449, 27% 	 train_loss: 3.37415e-05
Epoch 9449, 54% 	 train_loss: 3.46819e-05
Epoch 9449, 81% 	 train_loss: 8.14498e-05
Training loss = 2.14717e-04
Validation loss = 3.35128e-04
Training finished, took 170876.98s
Epoch 9450, 27% 	 train_loss: 4.26563e-05
Epoch 9450, 54% 	 train_loss: 3.36135e-05
Epoch 9450, 81% 	 train_loss: 4.75491e-05
Training loss = 1.58830e-04
Validation loss = 2.80697e-04
Training finished, took 170895.09s
Epoch 9451, 27% 	 train_loss: 2.99921e-05
Epoch 9451, 54% 	 train_loss: 2.44562e-05
Epoch 9451, 81% 	 train_loss: 4.08694e-05
Training loss = 1.32617e-04
Validation loss = 2.90201e-04
Training finished, took 170913.20s
Epoch 9452, 27% 	 train_loss: 2.75197e-05
Epoch 9452, 54% 	 train_loss: 2.89147e-05
Epoch 9452, 81% 	 train_loss: 5.40637e-05
Training loss = 1.56880e-04
Validation loss = 2.35173e-04
Training finished, took 170931.43s
Epoch 9453, 27% 	 train_loss: 4.43954e-05
Epoch 9453, 54% 	 train_loss: 3.31374e-05
Epoch 9453, 81% 	 train_loss: 8.12689e-05
Training loss = 2.18856e-04
Validation loss = 2.90939e-04
Training finished, took 170949.53s
Epoch 9454, 27% 	 train_loss: 3.53243e-05
Epoch 9454, 54% 	 train_loss: 2.55175e-05
Epoch 9454, 81% 	 train_loss: 3.97175e-05
Training loss = 1.31539e-04
Validation loss = 2.54552e-04
Training finished, took 170967.65s
Epoch 9455, 27% 	 train_loss: 3.90754e-05
Epoch 9455, 54% 	 train_loss: 2.80275e-05
Epoch 9455, 81% 	 train_loss: 4.77730e-05
Training loss = 1.54626e-04
Validation loss = 2.45940e-04
Training finished, took 170985.78s
Epoch 9456, 27% 	 train_loss: 2.91620e-05
Epoch 9456, 54% 	 train_loss: 3.48847e-05
Epoch 9456, 81% 	 train_loss: 8.20752e-05
Training loss = 1.96244e-04
Validation loss = 2.84868e-04
Training finished, took 171003.90s
Epoch 9457, 27% 	 train_loss: 3.75980e-05
Epoch 9457, 54% 	 train_loss: 4.03120e-05
Epoch 9457, 81% 	 train_loss: 7.86463e-05
Training loss = 2.02798e-04
Validation loss = 2.79275e-04
Training finished, took 171022.02s
Epoch 9458, 27% 	 train_loss: 3.42178e-05
Epoch 9458, 54% 	 train_loss: 3.52243e-05
Epoch 9458, 81% 	 train_loss: 5.30539e-05
Training loss = 1.59099e-04
Validation loss = 3.10006e-04
Training finished, took 171040.16s
Epoch 9459, 27% 	 train_loss: 5.02165e-05
Epoch 9459, 54% 	 train_loss: 3.10652e-05
Epoch 9459, 81% 	 train_loss: 4.22174e-05
Training loss = 1.61183e-04
Validation loss = 2.58998e-04
Training finished, took 171058.29s
Epoch 9460, 27% 	 train_loss: 2.99606e-05
Epoch 9460, 54% 	 train_loss: 2.63417e-05
Epoch 9460, 81% 	 train_loss: 6.09083e-05
Training loss = 1.59459e-04
Validation loss = 2.60962e-04
Training finished, took 171076.41s
Epoch 9461, 27% 	 train_loss: 3.04670e-05
Epoch 9461, 54% 	 train_loss: 3.92808e-05
Epoch 9461, 81% 	 train_loss: 7.79726e-05
Training loss = 1.99548e-04
Validation loss = 3.37749e-04
Training finished, took 171094.59s
Epoch 9462, 27% 	 train_loss: 4.44805e-05
Epoch 9462, 54% 	 train_loss: 3.34881e-05
Epoch 9462, 81% 	 train_loss: 5.15879e-05
Training loss = 1.65555e-04
Validation loss = 2.61028e-04
Training finished, took 171112.72s
Epoch 9463, 27% 	 train_loss: 3.54011e-05
Epoch 9463, 54% 	 train_loss: 2.99824e-05
Epoch 9463, 81% 	 train_loss: 5.68070e-05
Training loss = 1.66438e-04
Validation loss = 2.81017e-04
Training finished, took 171130.84s
Epoch 9464, 27% 	 train_loss: 3.60365e-05
Epoch 9464, 54% 	 train_loss: 3.80098e-05
Epoch 9464, 81% 	 train_loss: 8.85605e-05
Training loss = 2.20348e-04
Validation loss = 2.99560e-04
Training finished, took 171148.97s
Epoch 9465, 27% 	 train_loss: 3.42443e-05
Epoch 9465, 54% 	 train_loss: 3.04479e-05
Epoch 9465, 81% 	 train_loss: 5.40995e-05
Training loss = 1.55606e-04
Validation loss = 2.93993e-04
Training finished, took 171167.10s
Epoch 9466, 27% 	 train_loss: 4.35711e-05
Epoch 9466, 54% 	 train_loss: 3.42336e-05
Epoch 9466, 81% 	 train_loss: 4.18864e-05
Training loss = 1.62745e-04
Validation loss = 3.08462e-04
Training finished, took 171185.21s
Epoch 9467, 27% 	 train_loss: 3.90527e-05
Epoch 9467, 54% 	 train_loss: 2.66560e-05
Epoch 9467, 81% 	 train_loss: 6.21197e-05
Training loss = 1.78777e-04
Validation loss = 2.66296e-04
Training finished, took 171203.34s
Epoch 9468, 27% 	 train_loss: 2.86203e-05
Epoch 9468, 54% 	 train_loss: 3.00772e-05
Epoch 9468, 81% 	 train_loss: 6.86270e-05
Training loss = 1.69852e-04
Validation loss = 2.77264e-04
Training finished, took 171221.47s
Epoch 9469, 27% 	 train_loss: 2.76589e-05
Epoch 9469, 54% 	 train_loss: 3.59084e-05
Epoch 9469, 81% 	 train_loss: 6.56827e-05
Training loss = 1.72473e-04
Validation loss = 2.62953e-04
Training finished, took 171239.59s
Epoch 9470, 27% 	 train_loss: 4.06218e-05
Epoch 9470, 54% 	 train_loss: 3.64905e-05
Epoch 9470, 81% 	 train_loss: 4.75834e-05
Training loss = 1.57738e-04
Validation loss = 2.91372e-04
Training finished, took 171257.70s
Epoch 9471, 27% 	 train_loss: 3.65109e-05
Epoch 9471, 54% 	 train_loss: 2.91061e-05
Epoch 9471, 81% 	 train_loss: 4.23583e-05
Training loss = 1.43348e-04
Validation loss = 2.71567e-04
Training finished, took 171275.82s
Epoch 9472, 27% 	 train_loss: 3.38055e-05
Epoch 9472, 54% 	 train_loss: 2.81853e-05
Epoch 9472, 81% 	 train_loss: 5.27138e-05
Training loss = 1.60646e-04
Validation loss = 3.16273e-04
Training finished, took 171293.94s
Epoch 9473, 27% 	 train_loss: 3.92768e-05
Epoch 9473, 54% 	 train_loss: 3.41300e-05
Epoch 9473, 81% 	 train_loss: 4.98512e-05
Training loss = 1.64685e-04
Validation loss = 2.87231e-04
Training finished, took 171312.06s
Epoch 9474, 27% 	 train_loss: 3.07632e-05
Epoch 9474, 54% 	 train_loss: 2.59294e-05
Epoch 9474, 81% 	 train_loss: 4.30664e-05
Training loss = 1.43978e-04
Validation loss = 2.94662e-04
Training finished, took 171330.17s
Epoch 9475, 27% 	 train_loss: 2.88820e-05
Epoch 9475, 54% 	 train_loss: 2.59085e-05
Epoch 9475, 81% 	 train_loss: 4.42384e-05
Training loss = 1.40521e-04
Validation loss = 2.27321e-04
Training finished, took 171348.29s
Epoch 9476, 27% 	 train_loss: 3.89747e-05
Epoch 9476, 54% 	 train_loss: 3.30195e-05
Epoch 9476, 81% 	 train_loss: 9.77457e-05
Training loss = 2.43858e-04
Validation loss = 3.24428e-04
Training finished, took 171366.41s
Epoch 9477, 27% 	 train_loss: 2.85189e-05
Epoch 9477, 54% 	 train_loss: 2.79675e-05
Epoch 9477, 81% 	 train_loss: 4.33200e-05
Training loss = 1.31539e-04
Validation loss = 2.37462e-04
Training finished, took 171384.54s
Epoch 9478, 27% 	 train_loss: 3.81422e-05
Epoch 9478, 54% 	 train_loss: 2.59128e-05
Epoch 9478, 81% 	 train_loss: 4.43185e-05
Training loss = 1.48743e-04
Validation loss = 2.47655e-04
Training finished, took 171402.66s
Epoch 9479, 27% 	 train_loss: 3.15253e-05
Epoch 9479, 54% 	 train_loss: 3.14420e-05
Epoch 9479, 81% 	 train_loss: 7.45464e-05
Training loss = 1.87240e-04
Validation loss = 2.53603e-04
Training finished, took 171420.77s
Epoch 9480, 27% 	 train_loss: 3.40601e-05
Epoch 9480, 54% 	 train_loss: 3.06619e-05
Epoch 9480, 81% 	 train_loss: 5.15107e-05
Training loss = 1.52884e-04
Validation loss = 3.15733e-04
Training finished, took 171438.88s
Epoch 9481, 27% 	 train_loss: 4.04649e-05
Epoch 9481, 54% 	 train_loss: 3.15771e-05
Epoch 9481, 81% 	 train_loss: 4.22049e-05
Training loss = 1.52423e-04
Validation loss = 2.73371e-04
Training finished, took 171456.99s
Epoch 9482, 27% 	 train_loss: 4.18823e-05
Epoch 9482, 54% 	 train_loss: 2.71214e-05
Epoch 9482, 81% 	 train_loss: 5.18414e-05
Training loss = 1.64123e-04
Validation loss = 2.66758e-04
Training finished, took 171475.19s
Epoch 9483, 27% 	 train_loss: 3.08940e-05
Epoch 9483, 54% 	 train_loss: 2.96615e-05
Epoch 9483, 81% 	 train_loss: 5.74158e-05
Training loss = 1.59054e-04
Validation loss = 3.11929e-04
Training finished, took 171493.30s
Epoch 9484, 27% 	 train_loss: 3.53320e-05
Epoch 9484, 54% 	 train_loss: 3.37798e-05
Epoch 9484, 81% 	 train_loss: 4.43554e-05
Training loss = 1.53544e-04
Validation loss = 2.67789e-04
Training finished, took 171511.42s
Epoch 9485, 27% 	 train_loss: 3.75540e-05
Epoch 9485, 54% 	 train_loss: 2.89252e-05
Epoch 9485, 81% 	 train_loss: 5.46454e-05
Training loss = 1.62646e-04
Validation loss = 2.95149e-04
Training finished, took 171529.52s
Epoch 9486, 27% 	 train_loss: 2.70719e-05
Epoch 9486, 54% 	 train_loss: 3.04900e-05
Epoch 9486, 81% 	 train_loss: 5.27875e-05
Training loss = 1.46985e-04
Validation loss = 2.72553e-04
Training finished, took 171547.64s
Epoch 9487, 27% 	 train_loss: 4.39516e-05
Epoch 9487, 54% 	 train_loss: 3.11691e-05
Epoch 9487, 81% 	 train_loss: 5.02089e-05
Training loss = 1.67489e-04
Validation loss = 2.96467e-04
Training finished, took 171565.76s
Epoch 9488, 27% 	 train_loss: 5.11426e-05
Epoch 9488, 54% 	 train_loss: 2.79500e-05
Epoch 9488, 81% 	 train_loss: 5.79315e-05
Training loss = 1.83106e-04
Validation loss = 2.66580e-04
Training finished, took 171583.88s
Epoch 9489, 27% 	 train_loss: 3.48628e-05
Epoch 9489, 54% 	 train_loss: 3.23039e-05
Epoch 9489, 81% 	 train_loss: 9.37547e-05
Training loss = 2.31360e-04
Validation loss = 3.31444e-04
Training finished, took 171601.99s
Epoch 9490, 27% 	 train_loss: 3.99361e-05
Epoch 9490, 54% 	 train_loss: 2.92973e-05
Epoch 9490, 81% 	 train_loss: 6.18026e-05
Training loss = 1.70839e-04
Validation loss = 2.77379e-04
Training finished, took 171620.11s
Epoch 9491, 27% 	 train_loss: 3.64670e-05
Epoch 9491, 54% 	 train_loss: 2.92728e-05
Epoch 9491, 81% 	 train_loss: 5.09897e-05
Training loss = 1.52056e-04
Validation loss = 2.87696e-04
Training finished, took 171638.23s
Epoch 9492, 27% 	 train_loss: 3.80732e-05
Epoch 9492, 54% 	 train_loss: 3.82153e-05
Epoch 9492, 81% 	 train_loss: 8.50070e-05
Training loss = 2.19430e-04
Validation loss = 2.87911e-04
Training finished, took 171656.44s
Epoch 9493, 27% 	 train_loss: 4.02380e-05
Epoch 9493, 54% 	 train_loss: 3.82521e-05
Epoch 9493, 81% 	 train_loss: 8.02970e-05
Training loss = 2.13551e-04
Validation loss = 3.38323e-04
Training finished, took 171674.54s
Epoch 9494, 27% 	 train_loss: 4.50009e-05
Epoch 9494, 54% 	 train_loss: 3.23263e-05
Epoch 9494, 81% 	 train_loss: 4.59428e-05
Training loss = 1.59763e-04
Validation loss = 2.87201e-04
Training finished, took 171692.66s
Epoch 9495, 27% 	 train_loss: 3.53597e-05
Epoch 9495, 54% 	 train_loss: 2.63879e-05
Epoch 9495, 81% 	 train_loss: 4.18667e-05
Training loss = 1.38422e-04
Validation loss = 2.89275e-04
Training finished, took 171710.78s
Epoch 9496, 27% 	 train_loss: 2.74044e-05
Epoch 9496, 54% 	 train_loss: 3.59783e-05
Epoch 9496, 81% 	 train_loss: 6.97759e-05
Training loss = 1.83762e-04
Validation loss = 2.98204e-04
Training finished, took 171728.91s
Epoch 9497, 27% 	 train_loss: 5.36546e-05
Epoch 9497, 54% 	 train_loss: 3.98367e-05
Epoch 9497, 81% 	 train_loss: 5.38463e-05
Training loss = 1.83777e-04
Validation loss = 2.98158e-04
Training finished, took 171747.02s
Epoch 9498, 27% 	 train_loss: 2.99566e-05
Epoch 9498, 54% 	 train_loss: 2.73565e-05
Epoch 9498, 81% 	 train_loss: 4.44334e-05
Training loss = 1.40589e-04
Validation loss = 2.59781e-04
Training finished, took 171765.14s
Epoch 9499, 27% 	 train_loss: 3.32970e-05
Epoch 9499, 54% 	 train_loss: 2.97797e-05
Epoch 9499, 81% 	 train_loss: 4.95771e-05
Training loss = 1.58615e-04
Validation loss = 2.38805e-04
Training finished, took 171783.27s
Epoch 9500, 27% 	 train_loss: 3.05774e-05
Epoch 9500, 54% 	 train_loss: 3.77366e-05
Epoch 9500, 81% 	 train_loss: 6.15371e-05
Training loss = 1.71513e-04
Validation loss = 2.99402e-04
Training finished, took 171801.39s
Intermediate Plot Saved!
