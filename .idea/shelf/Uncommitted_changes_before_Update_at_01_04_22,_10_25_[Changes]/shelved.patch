Index: Main.py
===================================================================
diff --git a/Main.py b/Main.py
deleted file mode 100644
--- a/Main.py	(revision c3df8965a6d1f7dcf53ff29fd98f2088a130983b)
+++ /dev/null	(revision c3df8965a6d1f7dcf53ff29fd98f2088a130983b)
@@ -1,130 +0,0 @@
-from Mydataset import MyOwnDataset
-from MyDSS import MyOwnDSSNet
-from MyTrain import Train_DSS
-from MyCreateData import CreateData
-import argparse
-import sys
-import torch
-import os
-import shutil
-from torch_geometric.data import DataListLoader
-from torch_geometric.data import DataLoader
-import math
-
-parser = argparse.ArgumentParser()
-parser.add_argument('-e', '--n_epoch', help='epoch number', type=int, default=1)
-parser.add_argument('-r', '--restart', type=eval, default=False, choices=[True, False], help='Restart training option')
-parser.add_argument('-tcase', '--traincase', help='train cases', nargs="+", default=['40'])
-parser.add_argument('-vcase', '--valcase', help='validation cases', nargs="+", default=['40'])
-parser.add_argument('-n_out', '--n_output', help='output each n_out epoch', type=int, default=5)
-
-args = parser.parse_args()
-
-n_epoch = args.n_epoch
-restart = args.restart
-train_cases = args.traincase
-val_cases = args.valcase
-n_output = args.n_output
-
-# train_cases = ['40','50','60','70','80','90','100','120','130','140','150']
-# train_cases = ['40']
-# val_cases = ['40']
-# test_cases = ['110']
-
-## Copy Mesh file in Results - needed for plot ##
-for i in val_cases:
-    src = os.path.join("../Dataset", i, "Mesh.h5")
-    dst = "./Results/Mesh.h5"
-    shutil.copyfile(src, dst)
-
-## Setting blank for new execution ##
-if not restart:
-    if os.path.exists("./dataset/processed/data_val.pt"):
-        os.remove("./dataset/processed/data_val.pt")
-    if os.path.exists("./dataset/processed/data_train.pt"):
-        os.remove("./dataset/processed/data_train.pt")
-    if os.path.exists("./dataset/processed/pre_filter.pt"):
-        os.remove("./dataset/processed/pre_filter.pt")
-    if os.path.exists("./dataset/processed/pre_transform.pt"):
-        os.remove("./dataset/processed/pre_transform.pt")
-    if os.path.exists("./Model/best_model.pt"):
-        os.remove("./Model/best_model.pt")
-    if os.path.exists("./Model/best_model_normal_final.pt"):
-        os.remove("./Model/best_model_normal_final.pt")
-
-print("#################### DATA ADAPTING FOR GNN #######################")
-# createdata = CreateData()
-# createdata.transform(train_cases, 'train')
-# createdata.transform(val_cases, 'val')
-
-#set of parameter from second cycle optimization optuna
-k_list=[87]
-latent_dimension_list=[18]
-gamma_list=[0.1]
-alpha_list=[1e-2]
-lr_list=[3e-3]
-
-#check if gpu is available
-device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
-print('Running on : ', device)
-
-for k in k_list:
-    for latent_dimension in latent_dimension_list:
-        for gamma in gamma_list:
-            for alpha in alpha_list:
-                for lr in lr_list:
-
-                    set_name = str(k) +'-'+ str(latent_dimension).replace(".","") +'-'+ str(alpha).replace(".","") +'-'+ str(lr).replace(".","")
-                    print("PARAMETER SET: k:{}, laten_dim:{}, alpha:{}, lr:{}".format(str(k), str(latent_dimension), str(alpha), str(lr)))
-                    os.makedirs("./Results/" + set_name, exist_ok=True)
-                    os.makedirs("./Stats/" + set_name, exist_ok=True)
-
-                    print("#################### CREATING Inner DATASET #######################")
-                    loader_train = MyOwnDataset(root='./dataset', mode='train', cases=train_cases, device=device)
-                    loader_val = MyOwnDataset(root='./dataset', mode='val', cases=val_cases, device=device)
-
-                    #initialize the created dataset
-                    loader_train = DataLoader(loader_train, shuffle=True, batch_size=3) #opt args: shuffle, batchsize
-                    loader_val = DataLoader(loader_val)
-
-                    print("#################### DSS NET parameter #######################")
-
-                    #create hyperparameter
-                    latent_dimension = latent_dimension
-                    print("Latent space dim : ", latent_dimension)
-                    k = k
-                    print("Number of updates : ", k)
-                    gamma = gamma
-                    print("Gamma (loss function) : ", gamma)
-                    alpha = alpha
-                    print("Alpha (reduction correction) :", alpha)
-                    lr = lr
-                    print("LR (Learning rate):", lr)
-
-                    ##create folder for different results ##
-                    set_name = str(k) + '-' + str(latent_dimension).replace(".", "") + '-' + str(alpha).replace(".", "") + '-' + str(
-                        lr).replace(".", "")
-                    print("PARAMETER SET: k:{}, laten_dim:{}, alpha:{}, lr:{}".format(str(k), str(latent_dimension), str(alpha), str(lr)))
-                    os.makedirs("./Results/" + set_name, exist_ok=True)
-                    os.makedirs("./Stats/" + set_name, exist_ok=True)
-
-
-                    print("#################### CREATING NETWORKS #######################")
-                    DSS = MyOwnDSSNet(latent_dimension = latent_dimension, k = k, gamma = gamma, alpha = alpha, device=device)
-                    # # # DSS = DataParallel(DSS)
-                    DSS = DSS.to(device)
-                    # # #DSS = DSS.double()
-
-                    print("#################### TRAINING #######################")
-                    train_dss = Train_DSS(net=DSS, learning_rate=lr, n_epochs=n_epoch, device=device, set_name=set_name)
-
-                    optimizer, scheduler, epoch, min_val_loss = train_dss.createOptimizerAndScheduler()
-
-                    if restart:
-                        optimizer, scheduler, epoch, min_val_loss = train_dss.restart(optimizer, scheduler, path='Model/best_model.pt')
-
-                    GNN = train_dss.trainDSS(loader_train, loader_val, optimizer, scheduler, min_val_loss, epoch, k, n_output)
-                    #
-                    sys.stdout.flush()
-
-                    del DSS, GNN, loader_val, loader_train, optimizer, scheduler
Index: PostProcessing/MyPostProcess.py
===================================================================
diff --git a/PostProcessing/MyPostProcess.py b/PostProcessing/MyPostProcess.py
deleted file mode 100644
--- a/PostProcessing/MyPostProcess.py	(revision c3df8965a6d1f7dcf53ff29fd98f2088a130983b)
+++ /dev/null	(revision c3df8965a6d1f7dcf53ff29fd98f2088a130983b)
@@ -1,181 +0,0 @@
-from fenics import *
-import matplotlib.pyplot as plt
-import matplotlib.tri as tri
-import numpy as np
-import matplotlib as mpl
-from collections import OrderedDict
-from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable
-
-
-class PostProcess():
-    def __init__(self):
-        self.cmaps = OrderedDict()
-        self.cmaps['Perceptually Uniform Sequential'] = ['plasma_r']
-
-
-    def mesh2triang(self, mesh):
-        xy = mesh.coordinates()
-        return tri.Triangulation(xy[:, 0], xy[:, 1], mesh.cells())
-
-    def plot(self, obj):
-        # plt.gca().set_aspect('equal')
-        mesh = obj.function_space().mesh()
-
-        if isinstance(obj, Function):
-            if obj.vector().size() == mesh.num_cells():
-                C = obj.vector().array()
-                plt.tripcolor(self.mesh2triang(mesh), C, cmap=self.cmaps, norm='Normalize')
-
-            else:
-                x = mesh.coordinates()[:, 0]
-                y = mesh.coordinates()[:, 1]
-                t = mesh.cells()
-                v = obj.compute_vertex_values(mesh)
-                vmin = v.min()
-                vmax = v.max()
-                v[v < vmin] = vmin + 1e-12
-                v[v > vmax] = vmax - 1e-12
-                from matplotlib.ticker import ScalarFormatter
-                cmap = 'viridis'
-                levels = np.linspace(vmin, vmax, 100)
-                formatter = ScalarFormatter()
-                norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)
-                fig = plt.figure(figsize=(10, 5))
-                ax = fig.add_subplot(111)
-                c = ax.tricontourf(x, y, t, v, levels=levels, norm=norm,
-                                   cmap=plt.get_cmap(cmap))
-                plt.axis('equal')
-                p = ax.triplot(x, y, t, '-', lw=0.5, alpha=0.0)
-                ax.set_xlim([x.min(), x.max()])
-                ax.set_ylim([y.min(), y.max()])
-                ax.set_xlabel(' $\it{Coordinata\:x}$')
-                ax.set_ylabel(' $\it{Coordinata\:y}$')
-                # tit = plt.title('Componente x del tensore di Reynolds')
-                divider = make_axes_locatable(plt.gca())
-                cax = divider.append_axes('right', "4%", pad="2%")
-                colorbar_format = '% 1.1f'
-                cbar = plt.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax, format=colorbar_format)
-
-
-        elif isinstance(obj, Mesh):
-            plt.triplot(self.mesh2triang(obj), color='k')
-
-    def plot_results(self):
-        ####### loading mesh ########
-        mesh = Mesh()
-        mesh_file = "./Mesh.h5"
-        with HDF5File(MPI.comm_world, mesh_file, "r") as h5file:
-            h5file.read(mesh, "mesh", False)
-            facet = MeshFunction("size_t", mesh, mesh.topology().dim() - 1)
-            h5file.read(facet, "facet")
-
-        ####### initializing holder ########
-        VelocityElement = VectorElement("CG", mesh.ufl_cell(), 1)
-        PressureElement = FiniteElement("CG", mesh.ufl_cell(), 1)
-        Space = FunctionSpace(mesh, VelocityElement * PressureElement)
-
-        F = Function(Space)
-        v, f = F.split(deepcopy=True)
-
-        # with HDF5File(MPI.comm_world, "../Dataset/" + case_num + "/Results.h5", "r") as h5file:
-        #     h5file.read(f, "mean")
-        #     h5file.read(f, "forcing")
-
-        # ####### loading forcing from GNN ################
-        F_gnn = np.load("./results.npy").flatten()
-        mesh_points = mesh.coordinates().tolist()
-
-        dofs_coordinates_prev = Space.sub(0).collapse().tabulate_dof_coordinates().tolist()
-
-        for i, x in enumerate(mesh_points):
-            index = dofs_coordinates_prev.index(x)
-            v.vector()[(index)] = F_gnn[i * 2]
-            v.vector()[(index) + 1] = F_gnn[(i * 2) + 1]
-
-        ######### plot results ##############
-        plt.figure()
-        self.plot(v.sub(0))
-        plt.show()
-
-    def differences(self):
-        ####### loading mesh ########
-        mesh = Mesh()
-        mesh_file = "./Mesh.h5"
-        with HDF5File(MPI.comm_world, mesh_file, "r") as h5file:
-            h5file.read(mesh, "mesh", False)
-            facet = MeshFunction("size_t", mesh, mesh.topology().dim() - 1)
-            h5file.read(facet, "facet")
-
-        ####### initializing holder ########
-        VelocityElement = VectorElement("CG", mesh.ufl_cell(), 1)
-        PressureElement = FiniteElement("CG", mesh.ufl_cell(), 1)
-        Space = FunctionSpace(mesh, VelocityElement * PressureElement)
-
-        F_gnn = Function(Space)
-        v_gnn, f_gnn = F_gnn.split(deepcopy=True)
-
-        F_cfd = Function(Space)
-        v_cfd, f_cfd = F_cfd.split(deepcopy=True)
-
-        F_diff = Function(Space)
-        v_diff, f_diff = F_diff.split(deepcopy=True)
-
-
-        ######## loading forcing from GNN ################
-        F_gnn = np.load("./results.npy").flatten()
-
-        ######## loading forcing from CFD ################
-        F_cfd = np.load("./110/F.npy").flatten()
-
-        ######## mesh coordinates ##############
-        mesh_points = mesh.coordinates().tolist()
-
-        dofs_coordinates_prev = Space.sub(0).collapse().tabulate_dof_coordinates().tolist()
-
-        for i, x in enumerate(mesh_points):
-            index = dofs_coordinates_prev.index(x)
-            v_gnn.vector()[(index)] = F_gnn[i * 2]
-            v_gnn.vector()[(index) + 1] = F_gnn[(i * 2) + 1]
-
-        for i, x in enumerate(mesh_points):
-            index = dofs_coordinates_prev.index(x)
-            v_cfd.vector()[(index)] = F_cfd[i * 2]
-            v_cfd.vector()[(index) + 1] = F_cfd[(i * 2) + 1]
-
-        v_diff.vector()[:] = v_cfd.vector()[:] - v_gnn.vector()[:]
-
-        # #line value plotting for y=0.5 and 0<x<30
-        # x = np.arange(12,26,0.01)
-        #
-        # f_punti = []
-        #
-        # for i in x:
-        #     f_punti.append(v_cfd([i, 5]))
-        #
-        # y = []
-        # for i in f_punti:
-        #     y.append(i[0])
-
-
-        ######### plot results ##############
-        plt.figure()
-        self.plot(v_gnn.sub(0))
-        plt.show()
-        #
-        plt.figure()
-        self.plot(v_cfd.sub(0))
-        plt.show()
-
-        plt.figure()
-        self.plot(v_diff.sub(0))
-        plt.show()
-
-        print(f"Norma della differenza delle funzioni: {norm(v_diff, 'L2')}")
-        print(f"Norma della differenza delle funzioni normalizzata: {norm(v_diff, 'L2')/norm(v_cfd, 'L2')}")
-
-
-
-post_process = PostProcess()
-# post_process.plot_results()
-post_process.differences()
-
